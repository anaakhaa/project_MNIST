# -*- coding: utf-8 -*-
"""MNIST_ANN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QP0sT2u53wDX-GXqNEs_wm_H0jmABFkG
"""

#Installing dependencies
import numpy as np    #advanced math library
import tensorflow as tf
from tensorflow import keras
import seaborn as sn
import matplotlib.pyplot as plt       #for plotting

#The MNIST dataset is split into 60,000  28x28 pixel training images and 10,000 28x28 pixel images
(X_train,y_train),(X_test,y_test) = keras.datasets.mnist.load_data()

print("X_train shape", X_train.shape)
print("y_train shape", y_train.shape)
print("X_test shape", X_test.shape)
print("y_test shape", y_test.shape)

X_train[2]

#Scaling
X_train = X_train /255
X_test = X_test / 255

#After Scaling
X_train[0]

index=2
plt.imshow(X_train[index], cmap=plt.cm.plasma)
print(y_train[index])

X_train_flat = X_train.reshape(len(X_train), 28*28)
X_test_flat = X_test.reshape(len(X_test), 28*28)

X_train_flat.shape

# Building Model
model = keras.Sequential([
    keras.layers.Dense(128, input_shape=(784,), activation="relu"),
    keras.layers.Dense(64, activation="sigmoid"),
    keras.layers.Dense(32, activation="sigmoid"),
    keras.layers.Dense(10, activation="softmax"),  # Use softmax for multi-class classification
])

# Compiling Model
model.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])

# Training Model
model.fit(X_train_flat, y_train, epochs=5)

model.evaluate(X_test_flat,y_test)

y_pred = model.predict(X_test_flat)
y_pred_labels = [np.argmax(i) for i in y_pred]

confusion_matrix = tf.math.confusion_matrix(labels=y_test,predictions=y_pred_labels)
# Plotting confusion matrix
plt.figure(figsize=(10, 7))
sn.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()